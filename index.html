<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yufei Hu - PhD Candidate in Multimodal AI</title>
    <style>
        body {
            text-align: center;
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f9f9f9;
            color: #333;
        }
        .section {
            max-width: 800px;
            margin: 0 auto;
            text-align: left;
            padding: 20px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin-bottom: 30px;
        }
        h1, h2 {
            color: #2c3e50;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        ul {
            list-style-type: none;
            padding: 0;
        }
        li {
            margin-bottom: 10px;
        }
        img {
            width: 150px;
            border-radius: 50%;
            margin-top: 20px;
        }
    </style>
</head>
<body>

    <!-- Home Section -->
    <div class="section">
        <img src="Personnal_Photo.jpg" alt="Yufei Hu">
        <h1>Yufei Hu</h1>
        <p>PhD Candidate in <strong>Computer Science</strong> & <strong>Multimodal AI</strong> at ENSTA Paris, Institut Polytechnique de Paris, France.</p>
        <p><strong>Research Focus:</strong>: Multimodal AI, Vision-Language Integration, Edge Computing, and Self-Supervised Learning.</p>
        <p>Passionate about developing robust AI systems that bridge <strong>theoretical innovation</strong> with <strong>real-world applications</strong>, particularly in <strong>industrial</strong> and <strong>edge computing</strong> scenarios.</p>

        <p>Open to inquiries and collaborations.</p>

        <p>
            <a href="mailto:yufei.hu.2021@ensta-paris.fr">Email</a> / 
            <a href="https://github.com/flyingU-ai">GitHub</a> / 
            <a href="https://linkedin.com/in/yufei-hu-907598205">LinkedIn</a> / 
            <a href="https://scholar.google.com/citations?user=Ab_GbFwAAAAJ">Google Scholar</a>
        </p>
    </div>

    <!-- Research Interests Section -->
    <div class="section">
        <h2>Research Interests</h2>
        <p>My research interests lie at the intersection of <strong>Multimodal AI</strong>, <strong>Computer Vision</strong>, and <strong>Edge Computing</strong>, with a focus on:</p>
        <ul>
            <li><strong>Multimodal Fusion:</strong> Integrating vision, language, and spatial inputs for robust AI systems.</li>
            <li><strong>Self-Supervised Learning:</strong> Developing methods for learning representations with minimal supervision.</li>
            <li><strong>Model Distillation:</strong> Designing lightweight models for edge deployment.</li>
            <li><strong>Interactive AI:</strong> Building prompt-driven interfaces for human-AI collaboration.</li>
            <li><strong>Uncertainty Quantification:</strong> Enhancing model robustness through uncertainty-aware learning.</li>
        </ul>

        <p>If you have any projects or questions where collaboration could be beneficial, please don't hesitate to reach out to me.</p>
    </div>

    <!-- Education Section -->
    <div class="section">
        <h2>Education</h2>
        <ul>
            <li>
                <strong>Ecole Nationale Supérieure de Techniques Avancées (ENSTA Paris)</strong>
                <p>Master of Engineering in Information and Communication Sciences & Technologies</p>
                <p><em>Sep 2019 - Dec 2022</em></p>
            </li>
            <li>
                <strong>Chang'an University, Xi'an, China</strong>
                <p>Bachelor of Automation (Information and Control)</p>
                <p><em>Sep 2016 - Sep 2019</em></p>
            </li>
        </ul>
    </div>

    <!-- Research Experience Section -->
    <div class="section">
        <h2>Research Experience</h2>
        <ul>
            <li>
                <strong>Interactive Prompt-Based Object Detection with Cross-Modal Fusion</strong>
                <p>Developed a cross-modal framework integrating user prompts (e.g., clicks) with Vision Transformers via cross-attention and contrastive learning, enhancing adaptability for industrial inspection tasks.</p>
                <p><em>Jan 2024 - Present</em></p>
            </li>
            <li>
                <strong>CNN Model Distillation Based on SAM for Industrial Anomaly Detection</strong>
                <p>Designed a lightweight CNN by distilling knowledge from Segment Anything Model (SAM), achieving 91.3% F1-Score on a high-resolution PCBA dataset with 50ms inference latency on edge devices.</p>
                <p><em>Jun 2022 - Dec 2023</em></p>
            </li>
            <li>
                <strong>Semantic Image Synthesis with CGANs & Transformers</strong>
                <p>Achieved SOTA on Cityscapes, COCO-Stuff, and ADE20K via frequency-aware loss. Submitted to CVPR 2023.</p>
                <p><em>May 2022 - Oct 2022</em></p>
            </li>
        </ul>
    </div>

    <!-- Publications Section -->
    <div class="section">
        <h2>Publications</h2>
        <ul>
            <li>
                <strong>Learning Deep Morphological Networks with Neural Architecture Search</strong>
                <p>Yufei Hu, N. Belkhir, J. Angulo, A. Yao, G. Franchi. <em>Pattern Recognition</em>, 131, 108893, 2022 (SCI Q1, IF=8.518).</p>
                <p><a href="https://doi.org/10.1016/j.patcog.2022.108893">Paper Link</a></p>
            </li>
            <li>
                <strong>Robust Semantic Segmentation with Superpixel-Mix</strong>
                <p>G. Franchi, N. Belkhir, M. L. Ha, Yufei Hu, et al. <em>BMVC 2021</em>, 2021 (CCF-B).</p>
                <p><a href="https://arxiv.org/abs/xxxx">Paper Link</a></p>
            </li>
        </ul>
    </div>

    <!-- Patents Section -->
    <div class="section">
        <h2>Patents</h2>
        <ul>
            <li>
                <strong>Real-time Industrial Foreign Object Detection via Vision Foundation Models</strong>
                <p>Application Number: CN202410901829.2</p>
                <p>Developed a vision foundation model-based framework for real-time detection of foreign objects in industrial environments, achieving high precision in edge deployment.</p>
            </li>
            <li>
                <strong>Height Data Fusion with Texture-Guided Information Recovery and Real-Time Super-Resolution</strong>
                <p>Application Number: CN202410443098.1</p>
                <p>Innovated a multi-sensor fusion method to reconstruct high-resolution height maps using texture guidance, enhancing accuracy in 3D industrial inspection.</p>
            </li>
        </ul>
    </div>

</body>
</html>
